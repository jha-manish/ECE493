Logging to a2c
---------------------------------
| ep_len_mean        | 522      |
| ep_reward_mean     | -4.95    |
| explained_variance | -1.37    |
| fps                | 1537     |
| nupdates           | 1        |
| policy_entropy     | 2.08     |
| total_timesteps    | 10000    |
| value_loss         | 1.24     |
---------------------------------
---------------------------------
| ep_len_mean        | 597      |
| ep_reward_mean     | -4.86    |
| explained_variance | -1.23    |
| fps                | 1607     |
| nupdates           | 100      |
| policy_entropy     | 2.08     |
| total_timesteps    | 1000000  |
| value_loss         | 0.77     |
---------------------------------
---------------------------------
| ep_len_mean        | 590      |
| ep_reward_mean     | -4.89    |
| explained_variance | -0.973   |
| fps                | 1595     |
| nupdates           | 200      |
| policy_entropy     | 2.08     |
| total_timesteps    | 2000000  |
| value_loss         | 0.414    |
---------------------------------
---------------------------------
| ep_len_mean        | 592      |
| ep_reward_mean     | -4.88    |
| explained_variance | -0.417   |
| fps                | 1598     |
| nupdates           | 300      |
| policy_entropy     | 2.08     |
| total_timesteps    | 3000000  |
| value_loss         | 0.225    |
---------------------------------
---------------------------------
| ep_len_mean        | 594      |
| ep_reward_mean     | -4.81    |
| explained_variance | -0.0966  |
| fps                | 1587     |
| nupdates           | 400      |
| policy_entropy     | 2.08     |
| total_timesteps    | 4000000  |
| value_loss         | 0.182    |
---------------------------------
---------------------------------
| ep_len_mean        | 610      |
| ep_reward_mean     | -4.88    |
| explained_variance | -0.0343  |
| fps                | 1583     |
| nupdates           | 500      |
| policy_entropy     | 2.08     |
| total_timesteps    | 5000000  |
| value_loss         | 0.151    |
---------------------------------
---------------------------------
| ep_len_mean        | 606      |
| ep_reward_mean     | -4.83    |
| explained_variance | 0.271    |
| fps                | 1579     |
| nupdates           | 600      |
| policy_entropy     | 2.08     |
| total_timesteps    | 6000000  |
| value_loss         | 0.103    |
---------------------------------
---------------------------------
| ep_len_mean        | 597      |
| ep_reward_mean     | -4.86    |
| explained_variance | 0.295    |
| fps                | 1576     |
| nupdates           | 700      |
| policy_entropy     | 2.08     |
| total_timesteps    | 7000000  |
| value_loss         | 0.112    |
---------------------------------
---------------------------------
| ep_len_mean        | 613      |
| ep_reward_mean     | -4.79    |
| explained_variance | 0.438    |
| fps                | 1569     |
| nupdates           | 800      |
| policy_entropy     | 2.08     |
| total_timesteps    | 8000000  |
| value_loss         | 0.0829   |
---------------------------------
---------------------------------
| ep_len_mean        | 593      |
| ep_reward_mean     | -4.85    |
| explained_variance | 0.392    |
| fps                | 1562     |
| nupdates           | 900      |
| policy_entropy     | 2.08     |
| total_timesteps    | 9000000  |
| value_loss         | 0.093    |
---------------------------------
---------------------------------
| ep_len_mean        | 596      |
| ep_reward_mean     | -4.89    |
| explained_variance | 0.384    |
| fps                | 1558     |
| nupdates           | 1000     |
| policy_entropy     | 2.08     |
| total_timesteps    | 10000000 |
| value_loss         | 0.0918   |
---------------------------------
---------------------------------
| ep_len_mean        | 620      |
| ep_reward_mean     | -4.86    |
| explained_variance | 0.517    |
| fps                | 1558     |
| nupdates           | 1100     |
| policy_entropy     | 2.08     |
| total_timesteps    | 11000000 |
| value_loss         | 0.0696   |
---------------------------------
---------------------------------
| ep_len_mean        | 608      |
| ep_reward_mean     | -4.87    |
| explained_variance | 0.459    |
| fps                | 1557     |
| nupdates           | 1200     |
| policy_entropy     | 2.08     |
| total_timesteps    | 12000000 |
| value_loss         | 0.0774   |
---------------------------------
---------------------------------
| ep_len_mean        | 607      |
| ep_reward_mean     | -4.89    |
| explained_variance | 0.482    |
| fps                | 1562     |
| nupdates           | 1300     |
| policy_entropy     | 2.08     |
| total_timesteps    | 13000000 |
| value_loss         | 0.078    |
---------------------------------
---------------------------------
| ep_len_mean        | 607      |
| ep_reward_mean     | -4.92    |
| explained_variance | 0.498    |
| fps                | 1568     |
| nupdates           | 1400     |
| policy_entropy     | 2.08     |
| total_timesteps    | 14000000 |
| value_loss         | 0.0698   |
---------------------------------
---------------------------------
| ep_len_mean        | 655      |
| ep_reward_mean     | -4.85    |
| explained_variance | 0.505    |
| fps                | 1573     |
| nupdates           | 1500     |
| policy_entropy     | 2.08     |
| total_timesteps    | 15000000 |
| value_loss         | 0.0757   |
---------------------------------
---------------------------------
| ep_len_mean        | 609      |
| ep_reward_mean     | -4.86    |
| explained_variance | 0.592    |
| fps                | 1577     |
| nupdates           | 1600     |
| policy_entropy     | 2.08     |
| total_timesteps    | 16000000 |
| value_loss         | 0.0559   |
---------------------------------
---------------------------------
| ep_len_mean        | 616      |
| ep_reward_mean     | -4.85    |
| explained_variance | 0.587    |
| fps                | 1581     |
| nupdates           | 1700     |
| policy_entropy     | 2.08     |
| total_timesteps    | 17000000 |
| value_loss         | 0.0524   |
---------------------------------
---------------------------------
| ep_len_mean        | 626      |
| ep_reward_mean     | -4.79    |
| explained_variance | 0.446    |
| fps                | 1588     |
| nupdates           | 1800     |
| policy_entropy     | 2.07     |
| total_timesteps    | 18000000 |
| value_loss         | 0.106    |
---------------------------------
---------------------------------
| ep_len_mean        | 610      |
| ep_reward_mean     | -4.84    |
| explained_variance | 0.468    |
| fps                | 1602     |
| nupdates           | 1900     |
| policy_entropy     | 2.08     |
| total_timesteps    | 19000000 |
| value_loss         | 0.0978   |
---------------------------------
